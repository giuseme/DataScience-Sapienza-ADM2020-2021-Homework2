{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTLajaGgTNTu"
   },
   "source": [
    "# Homework 3 - Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slAB4Qg5TNTu"
   },
   "source": [
    "## 1. Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Yvi1l5UsTNTv"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq\n",
    "import requests\n",
    "import os\n",
    "from langdetect import detect\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aklNlcZ9TNTv"
   },
   "outputs": [],
   "source": [
    "# 1.1\n",
    "# Searching every page and writing the urls of the books in the file.\n",
    "\n",
    "f = open(\"List of books (URL).txt\", \"a\", encoding=\"utf-8\")\n",
    "\n",
    "n_books = []\n",
    "\n",
    "for k in range(0, 150):\n",
    "    my_url = \"https://www.goodreads.com/list/show/1.Best_Books_Ever?page=\"+str(k+1)\n",
    "    uClient = uReq(my_url)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    soup_i = soup(page_html, \"html.parser\")\n",
    "    books = soup_i.findAll(\"tr\")\n",
    "    n_books.append(len(books))\n",
    "    for i in range(len(books)):\n",
    "        item = books[i]\n",
    "        f.write(\"https://www.goodreads.com\"+item.a[\"href\"]+\"\\n\")\n",
    "    \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAZhxGyqTNTv"
   },
   "outputs": [],
   "source": [
    "# 1.2\n",
    "# Downloading the html pages of all the books contained in every page.\n",
    "\n",
    "f = open(\"List of books (URL).txt\", \"r\")\n",
    "\n",
    "num = 1\n",
    "\n",
    "for k in range(0, 150):\n",
    "    newpath = r\"Page \"+str(k+1)\n",
    "    os.makedirs(newpath)\n",
    "    for i in range(100):\n",
    "        my_url = f.readline()\n",
    "        uClient = uReq(my_url)\n",
    "        page_html = uClient.read()\n",
    "        uClient.close()\n",
    "        soup_i = soup(page_html, \"html.parser\")\n",
    "        f_new = open(newpath+\"/article_\"+str(num)+\".html\", \"w\", encoding=\"utf-8\")\n",
    "        f_new.write(str(soup_i))\n",
    "        f_new.close()\n",
    "        num += 1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDeHBJMwTNTv"
   },
   "outputs": [],
   "source": [
    "# 1.3\n",
    "# Acquiring all the information requested of the book pages and creating a tsv file for each of html file.\n",
    "\n",
    "num = 1\n",
    "for k in range(0, 150):\n",
    "    for i in range(100):\n",
    "        f = open(\"Page \"+str(k+1)+\"/article_\"+str(num)+\".html\", \"r\", encoding=\"utf-8\")\n",
    "        soup_i = soup(f.read(), \"html.parser\")\n",
    "        try:\n",
    "            Plot = soup_i.find(\"div\", {\"id\":\"description\"}).get_text().replace(\"\\n\", \"\").replace(\"...more\", \"\")\n",
    "        except:\n",
    "            Plot = \"Nessuna trama\"\n",
    "        if(detect(Plot)!=\"en\" or Plot==\"Nessuna trama\"):\n",
    "            f.close()\n",
    "            num += 1\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                bookTitle = soup_i.find(\"div\", {\"id\":\"metacol\"}).h1.contents[0].strip(\"\\n \")\n",
    "            except:\n",
    "                bookTitle = \"\"\n",
    "            try:\n",
    "                bookSeries = soup_i.find(\"div\", {\"id\":\"metacol\"}).h2.a.contents[0].strip(\"\\n \")\n",
    "            except:\n",
    "                bookSeries = \"\"\n",
    "            try:\n",
    "                bookAuthors = soup_i.find(\"a\", {\"class\":\"authorName\"}).span.contents[0].strip(\"\\n \")\n",
    "            except:\n",
    "                bookAuthors = \"\"\n",
    "            try:\n",
    "                ratingValue = soup_i.find(\"span\", {\"itemprop\":\"ratingValue\"}).contents[0].strip(\"\\n \")\n",
    "            except:\n",
    "                ratingValue = \"\"\n",
    "            try:\n",
    "                ratingCount = soup_i.findAll(\"a\", {\"href\":\"#other_reviews\"})[0].get_text().split(\"\\n\")[2].strip(\" \")\n",
    "            except:\n",
    "                ratingCount = \"\"\n",
    "            try:\n",
    "                reviewCount = soup_i.findAll(\"a\", {\"href\":\"#other_reviews\"})[1].get_text().split(\"\\n\")[2].strip(\" \")\n",
    "            except:\n",
    "                reviewCount = \"\"\n",
    "            try:\n",
    "                NumberofPages = soup_i.find(\"span\", {\"itemprop\":\"numberOfPages\"}).contents[0].split(\" \")[0]\n",
    "            except:\n",
    "                NumberofPages = \"\"\n",
    "            try:\n",
    "                PublishingDate = soup_i.findAll(\"div\", {\"class\":\"row\"})[1].get_text().split(\"\\n\")[2].strip(\" \")\n",
    "            except:\n",
    "                PublishingDate = \"\"\n",
    "            \n",
    "            Url = soup_i.find(\"link\")[\"href\"]\n",
    "            \n",
    "            # Different algorithm to retrieve Characters and Setting\n",
    "            try:\n",
    "                divs = soup_i.findAll(\"div\", class_=\"infoBoxRowItem\")\n",
    "                for div in divs:\n",
    "                    search = div.find(lambda tag: tag.name==\"a\" and re.match(r\"/places/\", str(tag.get(\"href\"))))\n",
    "                    if search:\n",
    "                        Setting = div\n",
    "                Setting = Setting.text.strip().replace(\"\\n\", \" \")\n",
    "            except:\n",
    "                Setting = \"\"\n",
    "            try:\n",
    "                ch = soup_i.findAll(lambda tag: tag.name==\"a\" and len(tag.attrs)==1 and re.match(r\"/characters/\", str(tag.get(\"href\"))))\n",
    "                l = []\n",
    "                for char in ch:\n",
    "                    l.append(char.text.strip())\n",
    "                Characters = (\" , \".join(l))\n",
    "            except:\n",
    "                Characters = \"\"\n",
    "            \n",
    "            f_new = open(\"Books tsv files/article_\"+str(num)+\".tsv\", \"a\", encoding=\"utf-8\")\n",
    "            l = [bookTitle, bookSeries, bookAuthors, ratingValue, ratingCount, reviewCount, Plot, NumberofPages, PublishingDate, Characters, Setting]\n",
    "            f_new.write(\" \\t \".join(l))\n",
    "            f_new.close()\n",
    "            num += 1\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "id": "hCOqywh_m3yX",
    "outputId": "655dacda-9068-4e2a-8fd9-a74a3949f216"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Harry Potter and the Order of the Phoenix</th>\n",
       "      <th>(Harry Potter #5)</th>\n",
       "      <th>J.K. Rowling</th>\n",
       "      <th>4.50</th>\n",
       "      <th>2,531,949</th>\n",
       "      <th>42,890</th>\n",
       "      <th>There is a door at the end of a silent corridor. And it’s haunting Harry Pottter’s dreams. Why else would he be waking in the middle of the night, screaming in terror?Harry has a lot on his mind for this, his fifth year at Hogwarts: a Defense Against the Dark Arts teacher with a personality like poisoned honey; a big surprise on the Gryffindor Quidditch team; and the loomiThere is a door at the end of a silent corridor. And it’s haunting Harry Pottter’s dreams. Why else would he be waking in the middle of the night, screaming in terror?Harry has a lot on his mind for this, his fifth year at Hogwarts: a Defense Against the Dark Arts teacher with a personality like poisoned honey; a big surprise on the Gryffindor Quidditch team; and the looming terror of the Ordinary Wizarding Level exams. But all these things pale next to the growing threat of He-Who-Must-Not-Be-Named - a threat that neither the magical government nor the authorities at Hogwarts can stop.As the grasp of darkness tightens, Harry must discover the true depth and strength of his friends, the importance of boundless loyalty, and the shocking price of unbearable sacrifice.His fate depends on them all.</th>\n",
       "      <th>870</th>\n",
       "      <th>September 2004</th>\n",
       "      <th>Sirius Black , Draco Malfoy , Ron Weasley , Petunia Dursley , Vernon Dursley , Dudley Dursley , Severus Snape , Rubeus Hagrid , Lord Voldemort , Minerva McGonagall , Neville Longbottom , Fred Weasley , George Weasley , Percy Weasley , Ginny Weasley , Colin Creevey , Filius Flitwick , Gilderoy Lockhart , Lucius Malfoy , Pomona Sprout , Arthur Weasley , Molly Weasley , Cho Chang , Cornelius Fudge , Remus Lupin , Sybil Trelawney , Stan Shunpike , Bellatrix Lestrange , Alastor Moody , Rita Skeeter , Luna Lovegood , Nymphadora Tonks , Dolores Umbridge , Dobby , Kingsley Shacklebolt , Padma Patil , Parvati Patil , Kreacher , Dean Thomas , Seamus Finnigan , Albus Dumbledore , Harry Potter , Hermione Granger , Lavender Brown</th>\n",
       "      <th>Hogwarts School of Witchcraft and Wizardry  (United Kingdom)   London, England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Harry Potter and the Order of the Phoenix ,  (Harry Potter #5) ,  J.K. Rowling ,  4.50 ,  2,531,949 ,  42,890 ,  There is a door at the end of a silent corridor. And it’s haunting Harry Pottter’s dreams. Why else would he be waking in the middle of the night, screaming in terror?Harry has a lot on his mind for this, his fifth year at Hogwarts: a Defense Against the Dark Arts teacher with a personality like poisoned honey; a big surprise on the Gryffindor Quidditch team; and the loomiThere is a door at the end of a silent corridor. And it’s haunting Harry Pottter’s dreams. Why else would he be waking in the middle of the night, screaming in terror?Harry has a lot on his mind for this, his fifth year at Hogwarts: a Defense Against the Dark Arts teacher with a personality like poisoned honey; a big surprise on the Gryffindor Quidditch team; and the looming terror of the Ordinary Wizarding Level exams. But all these things pale next to the growing threat of He-Who-Must-Not-Be-Named - a threat that neither the magical government nor the authorities at Hogwarts can stop.As the grasp of darkness tightens, Harry must discover the true depth and strength of his friends, the importance of boundless loyalty, and the shocking price of unbearable sacrifice.His fate depends on them all. ,  870 ,  September 2004 ,  Sirius Black , Draco Malfoy , Ron Weasley , Petunia Dursley , Vernon Dursley , Dudley Dursley , Severus Snape , Rubeus Hagrid , Lord Voldemort , Minerva McGonagall , Neville Longbottom , Fred Weasley , George Weasley , Percy Weasley , Ginny Weasley , Colin Creevey , Filius Flitwick , Gilderoy Lockhart , Lucius Malfoy , Pomona Sprout , Arthur Weasley , Molly Weasley , Cho Chang , Cornelius Fudge , Remus Lupin , Sybil Trelawney , Stan Shunpike , Bellatrix Lestrange , Alastor Moody , Rita Skeeter , Luna Lovegood , Nymphadora Tonks , Dolores Umbridge , Dobby , Kingsley Shacklebolt , Padma Patil , Parvati Patil , Kreacher , Dean Thomas , Seamus Finnigan , Albus Dumbledore , Harry Potter , Hermione Granger , Lavender Brown ,  Hogwarts School of Witchcraft and Wizardry  (United Kingdom)   London, England]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of tsv file considered as a dataframe\n",
    "pd.read_csv(\"Books tsv files/article_2.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A5isinDTNTv"
   },
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is implemented the search engine for conjunctive (AND) queries, with the plot as the considered attribute for pre-processing and the intersection with the query terms; all the plots are retrieved from their dataframes (tsv files) contained in folder \"Books tsv files\".\n",
    "The code blocks below take into consideration plots of the first 500 books and receive in input the query \"life journey\".\n",
    "The vocabulary and the indexes can be saved to a text or json file that can be opened before the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Vzx3LjllTNTv"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def pre_process(book_info):\n",
    "    book_info = re.sub(pattern=\" +\", repl=\" \", string=book_info)\n",
    "    words = re.sub(pattern=\"[^\\w\\s]\", repl=\"\", string=book_info)\n",
    "    words = [token for token in nlp(words) if not token.is_stop]\n",
    "    words = [token.lemma_ for token in words]\n",
    "    return [word.lower() for word in words]\n",
    "\n",
    "attrs = [\"bookTitle\", \"bookSeries\", \"bookAuthors\", \"ratingValue\", \"ratingCount\", \"reviewCount\", \"Plot\", \"NumberofPages\", \"PublishingDate\", \"Characters\", \"Setting\"]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWoEj4DtybeA",
    "outputId": "21dbc92f-8046-4357-9567-e579de15bbd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'door',\n",
       " 'end',\n",
       " 'silent',\n",
       " 'corridor',\n",
       " 'haunting',\n",
       " 'harry',\n",
       " 'pottters',\n",
       " 'dream',\n",
       " 'wake',\n",
       " 'middle',\n",
       " 'night',\n",
       " 'scream',\n",
       " 'terrorharry',\n",
       " 'lot',\n",
       " 'mind',\n",
       " 'fifth',\n",
       " 'year',\n",
       " 'hogwarts',\n",
       " 'defense',\n",
       " 'dark',\n",
       " 'arts',\n",
       " 'teacher',\n",
       " 'personality',\n",
       " 'like',\n",
       " 'poison',\n",
       " 'honey',\n",
       " 'big',\n",
       " 'surprise',\n",
       " 'gryffindor',\n",
       " 'quidditch',\n",
       " 'team',\n",
       " 'loomithere',\n",
       " 'door',\n",
       " 'end',\n",
       " 'silent',\n",
       " 'corridor',\n",
       " 'haunting',\n",
       " 'harry',\n",
       " 'pottters',\n",
       " 'dream',\n",
       " 'wake',\n",
       " 'middle',\n",
       " 'night',\n",
       " 'scream',\n",
       " 'terrorharry',\n",
       " 'lot',\n",
       " 'mind',\n",
       " 'fifth',\n",
       " 'year',\n",
       " 'hogwarts',\n",
       " 'defense',\n",
       " 'dark',\n",
       " 'arts',\n",
       " 'teacher',\n",
       " 'personality',\n",
       " 'like',\n",
       " 'poison',\n",
       " 'honey',\n",
       " 'big',\n",
       " 'surprise',\n",
       " 'gryffindor',\n",
       " 'quidditch',\n",
       " 'team',\n",
       " 'loom',\n",
       " 'terror',\n",
       " 'ordinary',\n",
       " 'wizarding',\n",
       " 'level',\n",
       " 'exam',\n",
       " 'thing',\n",
       " 'pale',\n",
       " 'grow',\n",
       " 'threat',\n",
       " 'hewhomustnotbename',\n",
       " ' ',\n",
       " 'threat',\n",
       " 'magical',\n",
       " 'government',\n",
       " 'authority',\n",
       " 'hogwart',\n",
       " 'stopas',\n",
       " 'grasp',\n",
       " 'darkness',\n",
       " 'tighten',\n",
       " 'harry',\n",
       " 'discover',\n",
       " 'true',\n",
       " 'depth',\n",
       " 'strength',\n",
       " 'friend',\n",
       " 'importance',\n",
       " 'boundless',\n",
       " 'loyalty',\n",
       " 'shocking',\n",
       " 'price',\n",
       " 'unbearable',\n",
       " 'sacrificehis',\n",
       " 'fate',\n",
       " 'depend']"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a pre_processed plot\n",
    "pre_process(pd.read_csv(\"Books tsv files/article_2.tsv\", sep=\"\\t\",\n",
    "                         names=attrs)[\"Plot\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "xGo0glfxTNTv"
   },
   "outputs": [],
   "source": [
    "# 2.1.1\n",
    "\n",
    "voc = {}\n",
    "inv_ind = {}\n",
    "id = 1\n",
    "for i in range(0, 500):\n",
    "    try:\n",
    "        ds = pd.read_csv(\"Books tsv files/article_\"+str(i+1)+\".tsv\", sep=\"\\t\",\n",
    "                          names=attrs)\n",
    "        words = pre_process(ds[\"Plot\"][0].replace(\".\", \". \"))\n",
    "        for word in words:\n",
    "            if word not in voc.keys():\n",
    "                voc[word]=id\n",
    "                id += 1\n",
    "        for word in list(set(words)):\n",
    "            if voc[word] not in inv_ind.keys():\n",
    "                inv_ind[voc[word]]=[]\n",
    "                inv_ind[voc[word]].append(i+1)\n",
    "            else:\n",
    "                inv_ind[voc[word]].append(i+1)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "#print(voc, sorted(inv_ind.items()))\n",
    "    \n",
    "#with open(\"vocabulary.txt\", \"w\") as vocabulary:\n",
    "    #vocabulary.write(str(voc))\n",
    "#with open(\"inv_index.txt\", \"w\") as inv_index:\n",
    "    #inv_index.write(str(inv_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drlqFggU8UeP",
    "outputId": "092ad24d-800e-4b32-bdb6-f071ebef7f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survive  :  2\n",
      "wild  :  3\n",
      "sure  :  4\n",
      "not  :  5\n",
      "live  :  6\n",
      "2  :  [1, 32, 45, 54, 56, 70, 86, 151, 168, 176, 187, 209, 214, 223, 230, 310, 320, 321, 325, 330, 375, 381, 388, 391, 402, 403, 407, 442, 455, 477, 485, 486, 499]\n",
      "3  :  [1, 26, 47, 51, 156, 181, 221, 242, 248, 257, 263, 280, 310, 393, 402, 440, 444, 473]\n",
      "4  :  [1, 34, 132, 241, 317, 343, 390, 454]\n",
      "5  :  [1, 5, 18, 22, 31, 37, 42, 44, 71, 84, 90, 92, 100, 103, 123, 132, 139, 140, 155, 165, 168, 173, 185, 187, 201, 202, 210, 213, 214, 218, 223, 224, 227, 239, 240, 241, 244, 269, 270, 284, 287, 306, 311, 317, 319, 321, 337, 339, 342, 343, 345, 350, 352, 356, 359, 369, 370, 382, 384, 390, 391, 393, 396, 402, 406, 418, 432, 435, 439, 443, 445, 446, 451, 452, 458, 477, 487, 488]\n",
      "6  :  [1, 21, 22, 26, 32, 37, 49, 61, 62, 75, 86, 96, 113, 121, 123, 131, 136, 144, 148, 154, 155, 157, 162, 165, 183, 195, 196, 208, 209, 214, 215, 218, 220, 231, 235, 240, 260, 263, 266, 267, 269, 270, 286, 289, 293, 305, 309, 311, 317, 326, 329, 343, 352, 363, 366, 375, 381, 384, 389, 394, 395, 407, 413, 424, 442, 447, 458, 460, 475, 482, 484, 488, 498]\n",
      "7  :  [1]\n"
     ]
    }
   ],
   "source": [
    "# Example of some words in vocabulary and some lines in inv_ind\n",
    "count = 0\n",
    "for key, value in voc.items():\n",
    "    if count<5 and key!=\" \":\n",
    "        print(key, \" : \", value)\n",
    "    count +=1\n",
    "count = 0\n",
    "for key, value in sorted(inv_ind.items()):\n",
    "    if count<=5 and key!=1:\n",
    "        print(key, \" : \", value\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "id": "zLWhxFTMTNTw",
    "outputId": "27f65934-50a8-4965-b26e-a1fc938b75df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life journey\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Room</td>\n",
       "      <td>To five-year-old-Jack, Room is the world....T...</td>\n",
       "      <td>https://www.goodreads.com/book/show/31685789-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Ultimate Hitchhiker's Guide to the Galaxy</td>\n",
       "      <td>At last in paperback in one complete volume, ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/13.The_Ult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lamb: The Gospel According to Biff, Christ's C...</td>\n",
       "      <td>The birth of Jesus has been well chronicled, ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/28881.Lamb\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eat, Pray, Love</td>\n",
       "      <td>A celebrated writer's irresistible, candid, a...</td>\n",
       "      <td>https://www.goodreads.com/book/show/19501.Eat_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City of Heavenly Fire</td>\n",
       "      <td>In this dazzling and long-awaited conclusion ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8755785-ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Subtle Knife</td>\n",
       "      <td>The second instalment in Philip Pullman’s His...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41637836-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Heart of Darkness</td>\n",
       "      <td>Heart of Darkness, a novel by Joseph Conrad, ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/4900.Heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Odyssey</td>\n",
       "      <td>Sing to me of the man, Muse, the man of twist...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1381.The_O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Unbroken: A World War II Story of Survival, Re...</td>\n",
       "      <td>In her long-awaited new book, Laura Hillenbra...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8664353-un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Slaughterhouse-Five</td>\n",
       "      <td>Selected by the Modern Library as one of the ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/4981.Slaug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Houdini Heart</td>\n",
       "      <td>HOUDINI HEART harkens back to the masters of ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/11324204-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dune</td>\n",
       "      <td>Set on the desert planet Arrakis, Dune is the...</td>\n",
       "      <td>https://www.goodreads.com/book/show/44767458-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mrs. Dalloway</td>\n",
       "      <td>Heralded as Virginia Woolf's greatest novel, ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/14942.Mrs_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Power of One</td>\n",
       "      <td>In 1939, as Hitler casts his enormous, cruel ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/122.The_Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Extremely Loud &amp; Incredibly Close</td>\n",
       "      <td>Nine-year-old Oskar Schell is an inventor, am...</td>\n",
       "      <td>https://www.goodreads.com/book/show/4588.Extre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Color Purple</td>\n",
       "      <td>Winner of the Pulitzer Prize and the National...</td>\n",
       "      <td>https://www.goodreads.com/book/show/52892857-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clockwork Prince</td>\n",
       "      <td>In the magical underworld of Victorian London...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10025305-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Interview with the Vampire</td>\n",
       "      <td>This is the story of Louis, as told in his ow...</td>\n",
       "      <td>https://www.goodreads.com/book/show/43763.Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Spirit Bound</td>\n",
       "      <td>Salvation has its price . . .The words stunne...</td>\n",
       "      <td>https://www.goodreads.com/book/show/6479259-sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Iliad/The Odyssey</td>\n",
       "      <td>Gripping listeners and readers for more than ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/1375.The_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cold Mountain</td>\n",
       "      <td>Cold Mountain is a novel about a soldier’s pe...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10920.Cold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Go Ask Alice</td>\n",
       "      <td>It started when she was served a soft drink l...</td>\n",
       "      <td>https://www.goodreads.com/book/show/46799.Go_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>She's Come Undone</td>\n",
       "      <td>In this extraordinary coming-of-age odyssey, ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/5203.She_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Eldest</td>\n",
       "      <td>Darkness falls…despair abounds…evil reigns…Er...</td>\n",
       "      <td>https://www.goodreads.com/book/show/45978.Elde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   ...                                                 11\n",
       "0                                               Room   ...  https://www.goodreads.com/book/show/31685789-r...\n",
       "1      The Ultimate Hitchhiker's Guide to the Galaxy   ...  https://www.goodreads.com/book/show/13.The_Ult...\n",
       "2   Lamb: The Gospel According to Biff, Christ's C...  ...   https://www.goodreads.com/book/show/28881.Lamb\\n\n",
       "3                                    Eat, Pray, Love   ...  https://www.goodreads.com/book/show/19501.Eat_...\n",
       "4                              City of Heavenly Fire   ...  https://www.goodreads.com/book/show/8755785-ci...\n",
       "5                                   The Subtle Knife   ...  https://www.goodreads.com/book/show/41637836-t...\n",
       "6                                  Heart of Darkness   ...  https://www.goodreads.com/book/show/4900.Heart...\n",
       "7                                        The Odyssey   ...  https://www.goodreads.com/book/show/1381.The_O...\n",
       "8   Unbroken: A World War II Story of Survival, Re...  ...  https://www.goodreads.com/book/show/8664353-un...\n",
       "9                                Slaughterhouse-Five   ...  https://www.goodreads.com/book/show/4981.Slaug...\n",
       "10                                     Houdini Heart   ...  https://www.goodreads.com/book/show/11324204-h...\n",
       "11                                              Dune   ...  https://www.goodreads.com/book/show/44767458-d...\n",
       "12                                     Mrs. Dalloway   ...  https://www.goodreads.com/book/show/14942.Mrs_...\n",
       "13                                  The Power of One   ...  https://www.goodreads.com/book/show/122.The_Po...\n",
       "14                 Extremely Loud & Incredibly Close   ...  https://www.goodreads.com/book/show/4588.Extre...\n",
       "15                                  The Color Purple   ...  https://www.goodreads.com/book/show/52892857-t...\n",
       "16                                  Clockwork Prince   ...  https://www.goodreads.com/book/show/10025305-c...\n",
       "17                        Interview with the Vampire   ...  https://www.goodreads.com/book/show/43763.Inte...\n",
       "18                                      Spirit Bound   ...  https://www.goodreads.com/book/show/6479259-sp...\n",
       "19                             The Iliad/The Odyssey   ...  https://www.goodreads.com/book/show/1375.The_I...\n",
       "20                                     Cold Mountain   ...  https://www.goodreads.com/book/show/10920.Cold...\n",
       "21                                      Go Ask Alice   ...  https://www.goodreads.com/book/show/46799.Go_A...\n",
       "22                                 She's Come Undone   ...  https://www.goodreads.com/book/show/5203.She_s...\n",
       "23                                            Eldest   ...  https://www.goodreads.com/book/show/45978.Elde...\n",
       "\n",
       "[24 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1.2\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#with open(\"vocabulary.txt\", \"r\") as vocabulary:\n",
    "    #voc = json.loads(voc.read())\n",
    "#with open(\"inv_index\", \"r\") as inv_index:\n",
    "    #inv_ind = json.loads(inv_index.read())\n",
    "\n",
    "# Alternatively (having already the json files for vocabulary and inverted_index):\n",
    "\n",
    "#with open(\"vocabulary.json\") as vocabulary:\n",
    "  #voc = json.load(vocabulary)\n",
    "#with open(\"inverted_index.json\") as inverted_index:\n",
    "  #inv_ind = json.load(inverted_index)\n",
    "    \n",
    "query = input().split(\" \")\n",
    "if len(query)==1:\n",
    "    if query[0] in voc.keys():\n",
    "        result = inv_ind[voc[query[0]]]\n",
    "    else:\n",
    "        result = []\n",
    "else:\n",
    "    l = []\n",
    "    for i in range(len(query)):\n",
    "        if query[i] in voc.keys():\n",
    "            l.append(inv_ind[voc[query[i]]])\n",
    "    for i in range(len(l)-1):\n",
    "        inter = list(set.intersection(set(l[i]), set(l[i+1])))\n",
    "        l[i+1] = inter\n",
    "    result = l[-1]\n",
    "\n",
    "data = []\n",
    "urls = []\n",
    "for doc_id in result:\n",
    "    f = open(\"List of books (URL).txt\", \"r\")\n",
    "    df = pd.read_csv(\"Books tsv files/article_\"+str(doc_id)+\".tsv\", sep=\"\\t\",\n",
    "                      names=attrs)\n",
    "    data.append(df)\n",
    "    for i in range(doc_id-1):\n",
    "        f.readline()\n",
    "    u = f.readline()\n",
    "    url = pd.DataFrame({\"Url\":[u]})\n",
    "    urls.append(url)\n",
    "    f.close()\n",
    "dataframe1 = pd.concat(data, axis=0, ignore_index=False)\n",
    "dataframe2 = pd.concat(urls, axis=0, ignore_index=False)\n",
    "\n",
    "dataframe = np.hstack([dataframe1, dataframe2])\n",
    "dataframe = pd.DataFrame(dataframe)\n",
    "dataframe.iloc[:, [0, 6, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-H0yDW_8TNTw"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def t_freq(term, doc):\n",
    "    count = 0\n",
    "    df = pd.read_csv(\"Books tsv files/article_\"+str(doc)+\".tsv\", sep=\"\\t\",\n",
    "                      names=attrs )\n",
    "    plot = pre_process(df[\"Plot\"][0])\n",
    "    for i in range(len(plot)):\n",
    "        if plot[i]==term:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def Idf(term):\n",
    "    N = len(inv_ind[voc[term]])\n",
    "    files = next(os.walk(\"Books tsv files\"))[2]\n",
    "    Idf = math.log10(len(files)/N)\n",
    "    return Idf\n",
    "\n",
    "def tfIdf(term, doc):\n",
    "    return t_freq(term, doc)*Idf(term)\n",
    "\n",
    "def cos_sim(query, doc_id, plot):\n",
    "    l = []\n",
    "    inter = list(set.intersection(set(query), set(plot)))\n",
    "    for q in inter:\n",
    "        for value in inv_ind2[voc[q]]:\n",
    "            if value[0]==doc_id:\n",
    "                l.append(value[1])\n",
    "    sim = (1/math.sqrt(len(query)))*(1/math.sqrt(len(plot)))*(sum(l))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHq9xywiTNTw"
   },
   "outputs": [],
   "source": [
    "# 2.2.1\n",
    "\n",
    "inv_ind2 = {}\n",
    "for key in voc.keys():\n",
    "    inv_ind2[voc[key]] = []\n",
    "    for doc in inv_ind[voc[key]]:\n",
    "        inv_ind2[voc[key]].append((doc, float(\"{:.1f}\".format(tfIdf(key, doc)))))\n",
    "#print(inv_ind2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AvXdthT_TbE",
    "outputId": "9d06dff1-5b0d-4060-88e2-2b1ea4c563e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  :  [(1, 5.3), (32, 2.6), (45, 2.6), (54, 2.6), (56, 2.6), (70, 5.3), (86, 5.3), (151, 2.6), (168, 2.6), (176, 2.6), (187, 2.6), (209, 2.6), (214, 2.6), (223, 5.3), (230, 5.3), (310, 2.6), (320, 2.6), (321, 5.3), (325, 5.3), (330, 5.3), (375, 5.3), (381, 2.6), (388, 2.6), (391, 5.3), (402, 2.6), (403, 2.6), (407, 5.3), (442, 5.3), (455, 5.3), (477, 2.6), (485, 5.3), (486, 2.6), (499, 5.3)]\n",
      "3  :  [(1, 5.8), (26, 2.9), (47, 5.8), (51, 8.7), (156, 5.8), (181, 5.8), (221, 2.9), (242, 5.8), (248, 2.9), (257, 5.8), (263, 2.9), (280, 2.9), (310, 2.9), (393, 2.9), (402, 5.8), (440, 2.9), (444, 5.8), (473, 2.9)]\n",
      "4  :  [(1, 6.5), (34, 6.5), (132, 3.2), (241, 6.5), (317, 3.2), (343, 3.2), (390, 6.5), (454, 6.5)]\n",
      "5  :  [(1, 4.5), (5, 2.3), (18, 4.5), (22, 2.3), (31, 4.5), (37, 4.5), (42, 4.5), (44, 2.3), (71, 4.5), (84, 4.5), (90, 2.3), (92, 2.3), (100, 4.5), (103, 2.3), (123, 2.3), (132, 2.3), (139, 2.3), (140, 4.5), (155, 4.5), (165, 4.5), (168, 6.8), (173, 4.5), (185, 4.5), (187, 9.0), (201, 9.0), (202, 2.3), (210, 2.3), (213, 2.3), (214, 6.8), (218, 2.3), (223, 2.3), (224, 13.5), (227, 18.0), (239, 2.3), (240, 4.5), (241, 11.3), (244, 2.3), (269, 2.3), (270, 4.5), (284, 2.3), (287, 6.8), (306, 6.8), (311, 9.0), (317, 15.8), (319, 2.3), (321, 4.5), (337, 6.8), (339, 2.3), (342, 4.5), (343, 2.3), (345, 2.3), (350, 2.3), (352, 4.5), (356, 13.5), (359, 9.0), (369, 2.3), (370, 2.3), (382, 4.5), (384, 2.3), (390, 4.5), (391, 9.0), (393, 2.3), (396, 11.3), (402, 11.3), (406, 4.5), (418, 9.0), (432, 2.3), (435, 9.0), (439, 2.3), (443, 6.8), (445, 6.8), (446, 4.5), (451, 2.3), (452, 2.3), (458, 4.5), (477, 9.0), (487, 4.5), (488, 2.3)]\n",
      "6  :  [(1, 9.1), (21, 2.3), (22, 2.3), (26, 4.6), (32, 6.8), (37, 2.3), (49, 2.3), (61, 2.3), (62, 4.6), (75, 2.3), (86, 4.6), (96, 2.3), (113, 4.6), (121, 2.3), (123, 2.3), (131, 4.6), (136, 2.3), (144, 13.7), (148, 4.6), (154, 2.3), (155, 4.6), (157, 2.3), (162, 4.6), (165, 2.3), (183, 2.3), (195, 2.3), (196, 2.3), (208, 4.6), (209, 2.3), (214, 2.3), (215, 2.3), (218, 6.8), (220, 2.3), (231, 2.3), (235, 4.6), (240, 9.1), (260, 4.6), (263, 9.1), (266, 4.6), (267, 4.6), (269, 11.4), (270, 2.3), (286, 2.3), (289, 4.6), (293, 4.6), (305, 2.3), (309, 4.6), (311, 2.3), (317, 2.3), (326, 2.3), (329, 2.3), (343, 9.1), (352, 11.4), (363, 6.8), (366, 9.1), (375, 4.6), (381, 2.3), (384, 2.3), (389, 2.3), (394, 9.1), (395, 2.3), (407, 4.6), (413, 2.3), (424, 4.6), (442, 6.8), (447, 2.3), (458, 2.3), (460, 4.6), (475, 9.1), (482, 4.6), (484, 4.6), (488, 2.3), (498, 2.3)]\n",
      "7  :  [(1, 8.3)]\n"
     ]
    }
   ],
   "source": [
    "# Example of some lines in inv_ind2\n",
    "count = 0\n",
    "for key, value in sorted(inv_ind2.items()):\n",
    "    if count<=5 and key!=1:\n",
    "        print(key, \" : \", value)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "Kyiap805TNTx",
    "outputId": "a2dfcb41-9a9d-4477-af2a-0cd971db6f70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life journey\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Power of One</td>\n",
       "      <td>In 1939, as Hitler casts his enormous, cruel ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/122.The_Po...</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interview with the Vampire</td>\n",
       "      <td>This is the story of Louis, as told in his ow...</td>\n",
       "      <td>https://www.goodreads.com/book/show/43763.Inte...</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Subtle Knife</td>\n",
       "      <td>The second instalment in Philip Pullman’s His...</td>\n",
       "      <td>https://www.goodreads.com/book/show/41637836-t...</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mrs. Dalloway</td>\n",
       "      <td>Heralded as Virginia Woolf's greatest novel, ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/14942.Mrs_...</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slaughterhouse-Five</td>\n",
       "      <td>Selected by the Modern Library as one of the ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/4981.Slaug...</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0   ...     12\n",
       "3            The Power of One   ...  0.838\n",
       "4  Interview with the Vampire   ...  0.721\n",
       "1            The Subtle Knife   ...  0.637\n",
       "2               Mrs. Dalloway   ...  0.598\n",
       "0         Slaughterhouse-Five   ...  0.546\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2.2\n",
    "import heapq\n",
    "\n",
    "query = input().split(\" \")\n",
    "if len(query)==1:\n",
    "    if query[0] in voc.keys():\n",
    "        result = []\n",
    "        for j in range(0, len(inv_ind2[voc[query[0]]])):\n",
    "                result.append(inv_ind2[voc[query[0]]][j][0])\n",
    "    else:\n",
    "        result = []\n",
    "else:\n",
    "    l1 = []\n",
    "    for i in range(len(query)):\n",
    "        l2 = []\n",
    "        if query[i] in voc.keys():\n",
    "            for j in range(0, len(inv_ind2[voc[query[i]]])):\n",
    "                l2.append(inv_ind2[voc[query[i]]][j][0])\n",
    "        l1.append(l2)\n",
    "    for i in range(len(l1)-1):\n",
    "        inter = list(set.intersection(set(l1[i]), set(l1[i+1])))\n",
    "        l1[i+1] = inter\n",
    "    result = l1[-1]\n",
    "\n",
    "data = []\n",
    "urls = []\n",
    "Similarities = []\n",
    "heap = []\n",
    "for doc_id in result:\n",
    "    df = pd.read_csv(\"Books tsv files/article_\"+str(doc_id)+\".tsv\", sep=\"\\t\",\n",
    "                      names=attrs)\n",
    "    if len(heap)<5:\n",
    "        heap.append((float(\"{:.3f}\".format(cos_sim(query, doc_id, pre_process(df[\"Plot\"][0])))), doc_id))\n",
    "    else:\n",
    "        heapq.heapify(heap)\n",
    "        heapq.heappushpop(heap, (float(\"{:.3f}\".format(cos_sim(query, doc_id, pre_process(df[\"Plot\"][0])))), doc_id))\n",
    "\n",
    "for el in heap:\n",
    "    if el[0]!=0.00:\n",
    "        df = pd.read_csv(\"Books tsv files/article_\"+str(el[1])+\".tsv\", sep=\"\\t\",\n",
    "                          names=attrs)\n",
    "        data.append(df)\n",
    "        f = open(\"List of books (URL).txt\", \"r\")\n",
    "        for i in range(el[1]-1):\n",
    "            f.readline()\n",
    "        u = f.readline()\n",
    "        url = pd.DataFrame({\"Url\":[u]})\n",
    "        urls.append(url)\n",
    "        f.close()\n",
    "        Similarity = pd.DataFrame({\"Similarity\":[float(\"{:.3f}\".format(cos_sim(query, el[1], pre_process(df[\"Plot\"][0]))))]})\n",
    "        Similarities.append(Similarity)\n",
    "    \n",
    "dataframe1 = pd.concat(data, axis=0, ignore_index=False)\n",
    "dataframe2 = pd.concat(urls, axis=0, ignore_index=False)\n",
    "dataframe3 = pd.concat(Similarities, axis=0, ignore_index=False)\n",
    "\n",
    "dataframe = np.hstack([dataframe1, dataframe2])\n",
    "dataframe = np.hstack([dataframe, dataframe3])\n",
    "\n",
    "# Top-k documents with k=5\n",
    "top_k = pd.DataFrame(dataframe).iloc[:, [0, 6, 11, 12]]\n",
    "top_k.sort_values([12], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wdBEXfLTNTx"
   },
   "source": [
    "## 3. Define a new score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13oySTVdTNTx"
   },
   "source": [
    "The new scoring function is designed to reward, in the search, the returned books whose plot is more related to the book's title and its setting. For this purpose the function simply counts how many times these two attributes occur in the plot; in addition to this, the frequency of the query in the plot is also taken into consideration.\n",
    "\n",
    "From this new scoring, fantasy and science-fiction books, for instance, are expected to obtain a higher score since their contents are intrinsically interwined with their fictional world.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nAHY7j5fTNTx"
   },
   "outputs": [],
   "source": [
    "def score_f(query, plot, title, setting):\n",
    "    count_q = 0\n",
    "    count_t = 0\n",
    "    count_s = 0\n",
    "    \n",
    "    for q in query:\n",
    "        for p in plot:\n",
    "            if p==q:\n",
    "                count_q += 1\n",
    "    for t in title:\n",
    "        for p in plot:\n",
    "            if p==t:\n",
    "                count_t += 1\n",
    "    for s in setting:\n",
    "        for p in plot:\n",
    "            if p==s:\n",
    "                count_s += 1\n",
    "              \n",
    "    return (count_q+count_t+count_s)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "i4AhH_iDTNTx",
    "outputId": "162d1a68-806a-41cb-f164-6898febcfeb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "life journey\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cold Mountain</td>\n",
       "      <td>Cold Mountain is a novel about a soldier’s pe...</td>\n",
       "      <td>https://www.goodreads.com/book/show/10920.Cold...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interview with the Vampire</td>\n",
       "      <td>This is the story of Louis, as told in his ow...</td>\n",
       "      <td>https://www.goodreads.com/book/show/43763.Inte...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mrs. Dalloway</td>\n",
       "      <td>Heralded as Virginia Woolf's greatest novel, ...</td>\n",
       "      <td>https://www.goodreads.com/book/show/14942.Mrs_...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eat, Pray, Love</td>\n",
       "      <td>A celebrated writer's irresistible, candid, a...</td>\n",
       "      <td>https://www.goodreads.com/book/show/19501.Eat_...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unbroken: A World War II Story of Survival, Re...</td>\n",
       "      <td>In her long-awaited new book, Laura Hillenbra...</td>\n",
       "      <td>https://www.goodreads.com/book/show/8664353-un...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   ...  12\n",
       "2                                     Cold Mountain   ...  24\n",
       "3                        Interview with the Vampire   ...  22\n",
       "4                                     Mrs. Dalloway   ...  16\n",
       "1                                   Eat, Pray, Love   ...  15\n",
       "0  Unbroken: A World War II Story of Survival, Re...  ...  13\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input().split(\" \")\n",
    "if len(query)==1:\n",
    "    if query[0] in voc.keys():\n",
    "        result = inv_ind[voc[query[0]]]\n",
    "    else:\n",
    "        result = []\n",
    "else:\n",
    "    l = []\n",
    "    for i in range(len(query)):\n",
    "        if query[i] in voc.keys():\n",
    "            l.append(inv_ind[voc[query[i]]])\n",
    "    for i in range(len(l)-1):\n",
    "        inter = list(set.intersection(set(l[i]), set(l[i+1])))\n",
    "        l[i+1] = inter\n",
    "    result = l[-1]\n",
    "    \n",
    "data = []\n",
    "urls = []\n",
    "Similarities = []\n",
    "heap = []\n",
    "for doc_id in result:\n",
    "    df = pd.read_csv(\"Books tsv files/article_\"+str(doc_id)+\".tsv\", sep=\"\\t\",\n",
    "                      names=attrs)\n",
    "    if len(heap)<5:\n",
    "        heap.append((score_f(query, pre_process(df[\"Plot\"][0]), pre_process(df[\"bookTitle\"][0]), pre_process(df[\"Setting\"][0])), doc_id))\n",
    "    else:\n",
    "        heapq.heapify(heap)\n",
    "        heapq.heappushpop(heap, (score_f(query, pre_process(df[\"Plot\"][0]), pre_process(df[\"bookTitle\"][0]), pre_process(df[\"Setting\"][0])), doc_id))\n",
    "\n",
    "for el in heap:\n",
    "    if el[0]!=0.00:\n",
    "        df = pd.read_csv(\"Books tsv files/article_\"+str(el[1])+\".tsv\", sep=\"\\t\",\n",
    "                          names=attrs)\n",
    "        data.append(df)\n",
    "        f = open(\"List of books (URL).txt\", \"r\")\n",
    "        for i in range(el[1]-1):\n",
    "            f.readline()\n",
    "        u = f.readline()\n",
    "        url = pd.DataFrame({\"Url\":[u]})\n",
    "        urls.append(url)\n",
    "        f.close()\n",
    "        Similarity = pd.DataFrame({\"Similarity\":[score_f(query, pre_process(df[\"Plot\"][0]), pre_process(df[\"bookTitle\"][0]), pre_process(df[\"Setting\"][0]))]})\n",
    "        Similarities.append(Similarity)\n",
    "    \n",
    "dataframe1 = pd.concat(data, axis=0, ignore_index=False)\n",
    "dataframe2 = pd.concat(urls, axis=0, ignore_index=False)\n",
    "dataframe3 = pd.concat(Similarities, axis=0, ignore_index=False)\n",
    "\n",
    "dataframe = np.hstack([dataframe1, dataframe2])\n",
    "dataframe = np.hstack([dataframe, dataframe3])\n",
    "\n",
    "# Top-k documents with k=5\n",
    "top_k = pd.DataFrame(dataframe).iloc[:, [0, 6, 11, 12]]\n",
    "top_k.sort_values([12], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9mtKctETNTx"
   },
   "source": [
    "## 5. Algorithmic Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1hO135pTTNTx"
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "def seq_len(string, ind):\n",
    "    if len(string)==1:\n",
    "        return 1\n",
    "    l1 = [j for j in range(0, len(string[:ind])) if string[j]<string[ind]]\n",
    "    if l1==[]:\n",
    "        return 1\n",
    "    else:\n",
    "        l2 = [seq_len(string, j) for j in l1]\n",
    "        return 1 + max(l2)\n",
    "\n",
    "def max_len(S):\n",
    "    l = []\n",
    "    for i in range(0, len(S)):\n",
    "        l.append(seq_len(S, i))\n",
    "    len_max_subseq = max(l)\n",
    "    return len_max_subseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Examples with 3 different strings\n",
    "S = \"CAD\"\n",
    "print(max_len(S))\n",
    "S = \"CADFECE\"\n",
    "print(max_len(S))\n",
    "S = \"CADFECEILGJHABNOPSTIRYOEABILCNR\"\n",
    "print(max_len(S))\n",
    "S1 = \"CADFECEILGJHABNOPSTIRYOEABILCNRASDFHGYTNROEITYMNBCJIURHTMSDFWERTKHMGFUQWERTYGJHKILMNMVDSDFGBVYCDEFGILMNOPTUVWFGBXDRTUNMKJLWSXCFL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The recursive algorithm proves correct and efficient when dealing with short and medium-length strings; however this is not the case for longer strings like $S1$, where the running time does not meet reasonable standards.\n",
    "2. The algorithm's running time is of course exponential since the function seq_len is called for every index of the string, meanwhile, due to the ricorsion, the same function is called for every $j$ of the string with $S[j]<S[i]$, $i$ being the index where the subsequence terminates. The expression of $T(n)$ can be derived from the one of Fibonacci function (recursive): this time seg_len function is called $f(n-1),...,f(0)$ times instead of two. It was shown in class that, using $T(n)>=2T(n-2)+const$ inequality, $T(n)$ is exponential. \n",
    "3.(See below)\n",
    "4. The new function below computes the result far more efficiently and way faster; the running time considered appears to be $O(n=len(S1))$, as the for loop goes all the way through the length of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "def dynam(S1):\n",
    "    lst_alph = []\n",
    "    lst_count = []\n",
    "    for char in S1:\n",
    "        if len(lst_alph)==0 or all(np.array(lst_alph)>=char):\n",
    "            count = 1\n",
    "        else:\n",
    "            indexes = np.array(lst_alph)<char\n",
    "            smaller_counts = np.array(lst_count)[indexes]\n",
    "            count = max(smaller_counts) + 1\n",
    "    \n",
    "        lst_alph.append(char)\n",
    "        lst_count.append(count)\n",
    "\n",
    "    print(max(lst_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "dynam(S1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework 3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
